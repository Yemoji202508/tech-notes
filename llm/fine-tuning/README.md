# 大模型微调基础知识

> 基于 LLaMA Factory 的大模型微调学习笔记，适合零基础入门

## 📚 目录

### 基础概念
1. [微调基础概念](./01_微调基础概念.md)
   - 什么是微调（通俗理解）
   - 微调的过程和优势
   - 微调 vs 提示词工程
   - 常见应用场景

### 核心技术
2. [LoRA 微调详解](./02_LoRA微调详解.md)
   - LoRA 原理（低秩适应）
   - 微调、推理、合并三阶段
   - QLoRA 和其他变体
   - 实战配置和代码示例

3. [模型量化详解](./03_模型量化详解.md)
   - 量化原理和精度类型（FP32/FP16/INT8/INT4）
   - 主流量化技术（GPTQ、AWQ、GGUF、BNB）
   - 量化方法对比和选择指南
   - 实战代码示例

### 评估方法
4. [模型评估方法](./04_模型评估方法.md)
   - 核心评估指标（困惑度、准确率、F1、BLEU、ROUGE）
   - 自动评估 vs 人工评估
   - 评估流程和工具
   - 评估报告模板

## 🎯 学习路径

### 新手入门（1-2 天）
```
第一步：理解微调概念
└─ 阅读《微调基础概念》

第二步：掌握核心技术
├─ 阅读《LoRA 微调详解》
└─ 阅读《模型量化详解》

第三步：学会评估模型
└─ 阅读《模型评估方法》
```

### 实战进阶（3-7 天）
```
第一步：环境搭建
└─ 安装 LLaMA Factory

第二步：跑通示例
├─ 下载示例数据集
├─ 运行 LoRA 微调
└─ 测试推理效果

第三步：自定义微调
├─ 准备自己的数据
├─ 调整训练参数
└─ 评估和优化
```

## 🔑 核心知识点

### 微调技术栈

```
┌─────────────────────────────────┐
│      应用层：业务场景           │
├─────────────────────────────────┤
│   评估层：指标和测试            │
├─────────────────────────────────┤
│ 微调层：LoRA/QLoRA              │
├─────────────────────────────────┤
│ 优化层：量化（4-bit/8-bit）     │
├─────────────────────────────────┤
│   基座层：预训练模型            │
└─────────────────────────────────┘
```

### 技术选型速查

| 场景 | 推荐方案 | 显存需求 | 训练时间 |
|------|---------|---------|---------|
| 快速实验 | LoRA + BNB 4-bit | 6GB | 1-2 小时 |
| 生产部署 | LoRA + AWQ 4-bit | 8GB | 2-4 小时 |
| 精度优先 | LoRA + 8-bit | 12GB | 4-8 小时 |
| 显存充足 | LoRA + FP16 | 24GB | 8-16 小时 |

### 常用命令速查

```bash
# 训练
llamafactory-cli train --config config.yaml

# 评估
llamafactory-cli eval --config config.yaml

# 推理
llamafactory-cli chat \
  --model_name_or_path meta-llama/Llama-3-8B \
  --adapter_name_or_path ./output/lora

# 合并
llamafactory-cli export \
  --model_name_or_path meta-llama/Llama-3-8B \
  --adapter_name_or_path ./output/lora \
  --export_dir ./output/merged
```

## 📖 专业术语表

| 术语 | 读音 | 含义 | 通俗理解 |
|------|------|------|---------|
| Fine-tuning | 微调 | 在预训练模型基础上继续训练 | 岗前培训 |
| LoRA | 洛拉 | 低秩适应微调方法 | 加装适配器 |
| QLoRA | Q-洛拉 | 量化 + LoRA | 压缩后加适配器 |
| Quantization | 量化 | 降低模型精度以减小体积 | 照片压缩 |
| GPTQ | G-P-T-Q | 训练后量化方法 | 离线压缩 |
| AWQ | A-W-Q | 激活感知量化 | 智能压缩 |
| Perplexity | 困惑度 | 模型预测的不确定性 | 惊讶程度 |
| BLEU | 布鲁 | 机器翻译评估指标 | 词汇重叠度 |
| ROUGE | 如日 | 文本摘要评估指标 | 召回率 |
| Epoch | 轮次 | 完整遍历一次训练数据 | 上一遍课 |
| Batch Size | 批大小 | 一次训练的样本数 | 每次教几个学生 |
| Learning Rate | 学习率 | 参数更新的步长 | 学习速度 |

## 🛠️ 工具和资源

### 必备工具
- **LLaMA Factory**：一站式微调框架
- **Hugging Face**：模型和数据集仓库
- **Weights & Biases**：训练监控和可视化

### 推荐资源
- [LLaMA Factory 官方文档](https://llamafactory.readthedocs.io/)
- [Hugging Face 课程](https://huggingface.co/course)
- [LoRA 论文](https://arxiv.org/abs/2106.09685)
- [QLoRA 论文](https://arxiv.org/abs/2305.14314)

### 社区和讨论
- [LLaMA Factory GitHub](https://github.com/hiyouga/LLaMA-Factory)
- [Hugging Face 论坛](https://discuss.huggingface.co/)
- [Reddit r/LocalLLaMA](https://www.reddit.com/r/LocalLLaMA/)

## ❓ 常见问题

### Q1：需要什么硬件配置？

**最低配置**（QLoRA 4-bit）：
- GPU：RTX 3060 12GB
- 内存：16GB
- 硬盘：50GB SSD

**推荐配置**（LoRA 8-bit）：
- GPU：RTX 4090 24GB
- 内存：32GB
- 硬盘：100GB SSD

### Q2：需要多少训练数据？

```
任务类型          最少      推荐      理想
简单分类          500      2,000     5,000+
问答系统         1,000     5,000    10,000+
代码生成         2,000    10,000    50,000+
```

### Q3：训练需要多长时间？

```
模型大小    数据量    显卡        时间
7B         5,000    RTX 4090    2-4 小时
13B        5,000    RTX 4090    4-8 小时
70B        5,000    A100 80GB   8-16 小时
```

### Q4：如何判断微调效果？

1. **定量指标**：准确率、F1 分数等
2. **定性分析**：人工抽查 50-100 样本
3. **A/B 测试**：对比原始模型和微调模型
4. **真实场景**：在实际业务中小规模试用

### Q5：微调失败怎么办？

**常见问题和解决方案**：

```
问题：显存不足（OOM）
解决：
- 降低 batch_size
- 使用 4-bit 量化
- 减小 lora_rank
- 启用梯度检查点

问题：损失不下降
解决：
- 检查数据格式
- 调整学习率
- 增加训练轮数
- 检查标签质量

问题：过拟合
解决：
- 增加训练数据
- 增大 dropout
- 减少训练轮数
- 使用数据增强
```

## 📝 学习笔记

### 关键要点

1. **微调不是魔法**
   - 不能让模型学会全新知识
   - 主要是激活和强化已有能力
   - 数据质量决定效果上限

2. **LoRA 是首选**
   - 成本低、效果好、灵活性高
   - 适合 99% 的微调场景
   - 从 rank=8 开始实验

3. **量化是必需**
   - 4-bit 是甜点（平衡精度和效率）
   - 训练用 BNB，推理看场景
   - 量化后精度损失 2-3%

4. **评估要全面**
   - 不依赖单一指标
   - 自动评估 + 人工抽查
   - 真实场景测试最重要

### 实战经验

```
✅ 做的对的：
- 从小模型开始（7B）
- 使用高质量数据（少而精）
- 多次实验找最佳参数
- 详细记录每次实验

❌ 常见错误：
- 一上来就用 70B 模型
- 数据量大但质量差
- 只看训练损失不看测试
- 过早优化和调参
```

## 🎓 进阶方向

掌握基础后，可以探索：

1. **高级微调技术**
   - Full Fine-tuning（全量微调）
   - Prefix Tuning（前缀微调）
   - P-Tuning v2（提示微调）

2. **多模态微调**
   - 视觉语言模型（VLM）
   - 语音识别模型

3. **强化学习**
   - RLHF（人类反馈强化学习）
   - DPO（直接偏好优化）

4. **模型压缩**
   - 知识蒸馏
   - 剪枝
   - 混合精度训练

## 📅 更新日志

- **2025-11-15**：创建初始版本
  - 完成 4 篇基础教程
  - 涵盖微调、LoRA、量化、评估

---

**参考资料**：
- LLaMA Factory 官方文档
- Hugging Face Transformers 文档
- 相关学术论文

**贡献者**：个人学习笔记

**许可**：仅供学习参考
